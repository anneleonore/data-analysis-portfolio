{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee3a91e-a61e-4bee-892e-39c48504721c",
   "metadata": {},
   "source": [
    "# Data Analysis Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd32e9-b78b-4a71-9663-b958235f5b66",
   "metadata": {},
   "source": [
    "This notebook is part of my data analysis portfolio, where I explore **three** key areas:\n",
    "1. Data processing and visualization\n",
    "2. Data science and machine learning\n",
    "3. Text analysis and insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694eb9a-2dfa-40a6-901e-57f57eecea94",
   "metadata": {},
   "source": [
    "## <span style=\"background-color: #FFE5B4 \">  Section 1. Data Processing and Visualization </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7aeb4-64be-459a-be5f-51dd5dc26f68",
   "metadata": {},
   "source": [
    "### General information\n",
    "There are various important packages for *data processing and visualization*. In the example code below, I will be focusing on:\n",
    "- pandas\n",
    "- numpy\n",
    "- statsmodel\n",
    "- matplotlib\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f29eca-8a95-4478-8d71-5f8f6115259a",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4b51b-bb6a-43eb-923d-5f02c643fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages/modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941599b4-e905-4305-bce6-8f3b43e29802",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #FFE5B4 \">1.1 Data Processing</span>\n",
    "\n",
    "<a href=\"https://www.fullstory.com/blog/what-is-data-processing/\">Data processing</a> is a series of operations performed on data to transform, analyze, and organze it in a useful format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c57e068-8120-4820-baa3-25b4d2f0d5b2",
   "metadata": {},
   "source": [
    "#### 1.1.1 Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a208a8-7ea8-448e-8c47-91a00ec3f9fa",
   "metadata": {},
   "source": [
    "#### 1.1.2 Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe56dec-caab-4416-bb34-3c67ebd57d47",
   "metadata": {},
   "source": [
    "#### 1.1.3 Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde09302-4c65-4d28-b951-0737a778b123",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #FFE5B4 \">1.2 Data Visualization</span>\n",
    "\n",
    "<a href=\"https://www.tableau.com/learn/articles/data-visualization\">Data visualization</a> is the graphical representation of data through use of visual elements, such as charts, graphs, plots, and infographics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a784b-55f9-442c-a077-ece6db194c1c",
   "metadata": {},
   "source": [
    "#### 1.2.1 Static"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb5e65-52f6-4fdf-8e10-2730870a12c5",
   "metadata": {},
   "source": [
    "#### 1.2.2 Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8aa97-2568-4af0-b5d9-f19dca88aea9",
   "metadata": {},
   "source": [
    "<hr style=\"border: 0.8px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc6c66-b979-4a0f-9746-deb18aaacab1",
   "metadata": {},
   "source": [
    "## <span style=\"background-color: #FFE5B4 \"> Section 2. Traditional Machine Learning and Deep Learning </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34669a01-d0ee-44b6-a16d-958a97da61fe",
   "metadata": {},
   "source": [
    "### General information\n",
    "There are various important packages for *traditional machine learning and deep learning*. In the example code below, I will be focusing on:\n",
    "- pytorch\n",
    "- scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2139b-0343-41ee-884d-615ec4461010",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c29ffa8-1e6c-4c90-b0fd-2527aeada754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import packages/modules\n",
    "import sklearn as sk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#Import specific objects\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de3563-ca31-4af8-aad0-ef66763b6648",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #FFE5B4 \">2.1 Traditional Machine Learning</span>\n",
    "scikit-learn is focused on traditional machine learning tasks, such as linear regression, clustering, and support vector machines (CVMs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1efb62-8246-44f5-a825-67de2892d6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ba05eaf-1b24-438d-bb8f-3da5c2545ec2",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #FFE5B4 \">2.2 Deep Learning</span>\n",
    "PyTorch is primarily designed for deep learning tasks, such as neural networks (CNNs, RNNs) and transformers (BERT, RoBERTa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ce277-5b3b-44bb-b743-f04d5c8ec9e5",
   "metadata": {},
   "source": [
    "#### Important terminology: PyTorch\n",
    "- **backpropagation**: The process of adjusting the weights of a neural network by analyzing the error rate from the previous iteration.\n",
    "- **batch**: A hyperparameter that defines the number of samples that are processed before the interal model parameters are updated.\n",
    "- **Dataset**: Data primitive that stores the samples and their corresponding labels.\n",
    "- **DataLoader**: Data primitive that wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "- **gradient descent**: An iterative optimization method that minimises the loss function in machine learning models.\n",
    "- **epoch**: A hyperparameter that defines the number of complete passes through the training dataset.\n",
    "- **hyperparameter**: A parameter that is set before the machine learning process begins.\n",
    "- **learning rate**: A hyperparameter that controls the step size of each gradient descent update.\n",
    "- **loss function**: A mathematical function that measures the difference between the model's predictions and the actual labels.\n",
    "- **Model**: A neural network architecture that is designed to solve a specific problem.\n",
    "- **module**: Base class for all neural network models (the building blocks).\n",
    "- **neural network**: A machine learning program/model that makes decisions in a manner similar to the human brain.\n",
    "- **optimizer**: A tool that helps with the process of training a machine learning model.\n",
    "- **sample**: A single row of data.\n",
    "- **tensor**: A multi-dimensional array of numerical values (a \"container\" for data).\n",
    "    - A tensor can be created by running: torch.ones(r,c) or torch.rand(r,c).\n",
    "    - Tensors of similar shapes can be added, multiplied, etc.\n",
    "- **ToTensor**: Transformation function that converts NumPy array into PyTorch tensor representation. \n",
    "- **training**: The process of adjusting the model's parameters to minimize the loss function.\n",
    "- **validation**: The process of evaluating the model's parameters on a separate dataset to monitor overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d385e95a-a40d-40cc-8c78-4de0f5785189",
   "metadata": {},
   "source": [
    "#### PyTorch dataset: YelpReviewFull\n",
    "Find more information about this dataset: https://huggingface.co/datasets/Yelp/yelp_review_full\n",
    "\n",
    "**Data Fields**\n",
    "- *text*: The review texts are escaped using double quotes (\"), and any internal double quote is escaped by 2 double quotes (\"\"). New lines are escaped by a backslash followed with an \"n\" character, that is \"\\n\".\n",
    "- *label*: Corresponds to the score associated with the review (between 1 and 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccdf748e-880f-4a0b-a9ae-ff984d8c78d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset information\n",
      "________________________________________\n",
      "\n",
      "Type<class 'datasets.dataset_dict.DatasetDict'>\n",
      "\n",
      "Length: 2\n",
      "\n",
      "Dataset structure: {'train': ['label', 'text'], 'test': ['label', 'text']}\n",
      "\n",
      "Dataset overview: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 650000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n",
      "\n",
      "First row in train set:\n",
      "Label: 4\n",
      "Text: dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\n",
      "\n",
      "First row in test set:\n",
      "Label: 0\n",
      "Text: I got 'new' tires from them and within two weeks got a flat. I took my car to a local mechanic to see if i could get the hole patched, but they said the reason I had a flat was because the previous patch had blown - WAIT, WHAT? I just got the tire and never needed to have it patched? This was supposed to be a new tire. \\nI took the tire over to Flynn's and they told me that someone punctured my tire, then tried to patch it. So there are resentful tire slashers? I find that very unlikely. After arguing with the guy and telling him that his logic was far fetched he said he'd give me a new tire \\\"this time\\\". \\nI will never go back to Flynn's b/c of the way this guy treated me and the simple fact that they gave me a used tire!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import dataset through Huggingface dataset\n",
    "#ds_yelp = load_dataset(\"Yelp/yelp_review_full\")\n",
    "\n",
    "#Include print statements to see data structure\n",
    "print(\"Dataset information\")\n",
    "print(\"_\" * 40 + \"\\n\")\n",
    "\n",
    "print(f\"Type{(type(ds_yelp))}\")\n",
    "print()\n",
    "\n",
    "print(f\"Length: {len(ds_yelp)}\")\n",
    "print()\n",
    "\n",
    "print(f\"Dataset structure: {ds_yelp.column_names}\")\n",
    "print()\n",
    "\n",
    "print(f\"Dataset overview: {ds_yelp}\")\n",
    "print()\n",
    "\n",
    "print(\"First row in train set:\")\n",
    "print(f\"Label: {ds_yelp['train']['label'][0]}\")\n",
    "print(f\"Text: {ds_yelp['train']['text'][0]}\")\n",
    "print()\n",
    "\n",
    "print(\"First row in test set:\")\n",
    "print(f\"Label: {ds_yelp['test']['label'][0]}\")\n",
    "print(f\"Text: {ds_yelp['test']['text'][0]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ecb491-65e7-43c7-94e1-a6eac9d2e839",
   "metadata": {},
   "source": [
    "<hr style=\"border: 0.8px solid black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614d506-a500-467c-8a9c-c3d2b576e716",
   "metadata": {},
   "source": [
    "## <span style=\"background-color: #FFE5B4 \"> Section 3. Text Sentiment and Topic Modeling </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fad411-1a81-42b6-bca7-1ab07ec0943b",
   "metadata": {},
   "source": [
    "### General information\n",
    "There are various important packages for *text sentiment and topic modeling*. In the example code below, I will be focusing on:\n",
    "- nltk\n",
    "- spacy\n",
    "- gensim\n",
    "- transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb807ef8-9fbb-49c7-96f7-125f518c4bda",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04a43f-8d4f-45c3-9214-a0aeb59a25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages/modules\n",
    "import gensim\n",
    "import nltk\n",
    "import spacy\n",
    "import transformers\n",
    "\n",
    "#Import specific objects\n",
    "from gensim.models import Word2Vec, TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from spacy import displacy\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af502b1-7261-4ecb-a24a-d7959393c5e3",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #FFE5B4 \">3.1 Text Sentiment</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485289f7-4c55-4e1a-9ee6-2e70e52bc909",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #FFE5B4 \">3.2 Topic Modeling</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea99946-e8e3-4f0c-9a9b-9dce7a4cd055",
   "metadata": {},
   "source": [
    "## License and Copyright"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a8844-808d-4207-8fcf-122d74389b8a",
   "metadata": {},
   "source": [
    "Â© 2024 Noor de Bruijn. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-myenv",
   "language": "python",
   "name": "data-analysis-myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
