{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f62e4b6d-8a6b-48a1-8b8e-5609d75570b2",
   "metadata": {},
   "source": [
    "# Data Analysis Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b64203-ee47-4bee-818f-60c7fb5c1a55",
   "metadata": {},
   "source": [
    "This notebook is part of my data analysis portfolio, where I explore **three** key areas:\n",
    "1. Data Processing and Visualization\n",
    "2. Traditional Machine Learning and Deep Learning\n",
    "3. Text Sentiment and Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff3ecaa5-4304-4454-ac87-48e7d25b02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import general packages\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ce203-4279-4310-bdb6-7ef040e79882",
   "metadata": {},
   "source": [
    "## <span style=\"background-color: #FFE5B4 \"> Section 3. Text Sentiment and Topic Modeling </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c04fb6-5eb4-4afc-b94e-80ba0220beae",
   "metadata": {},
   "source": [
    "### General information\n",
    "There are various important packages for *text sentiment and topic modeling*. In the example code below, I will be focusing on:\n",
    "- nltk\n",
    "- spacy\n",
    "- gensim\n",
    "- transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5fea6-7a69-4392-b817-338cb4a4994c",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab616fb1-4c8b-42a8-8acc-a9cfdb478665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages/modules\n",
    "import gensim\n",
    "import nltk\n",
    "import spacy\n",
    "import transformers\n",
    "\n",
    "#Import specific objects\n",
    "from gensim.models import Word2Vec, TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from spacy import displacy\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da612e-6c15-4f4f-acdb-9fa49c870327",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #FFE5B4 \">3.1 Text Sentiment</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1db3ea-5134-42c4-9210-fdbfcbaf8b20",
   "metadata": {},
   "source": [
    "### <span style=\"background-color: #FFE5B4 \">3.2 Topic Modeling</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75da8dd1-7b59-4138-a8ef-752317af4856",
   "metadata": {},
   "source": [
    "## License and Copyright"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e74df99-7003-4973-9375-79fc9d723806",
   "metadata": {},
   "source": [
    "Â© 2024 Noor de Bruijn. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-myenv",
   "language": "python",
   "name": "data-analysis-myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
